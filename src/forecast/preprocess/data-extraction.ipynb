{"cells":[{"cell_type":"markdown","metadata":{},"source":["## BigQuery -  Github\n","This basic Python kernel shows you how to query the `commits` table in the GitHub Repos BigQuery dataset. We will use this information to obatin a representative sample of all the public repositories at Github. To run this notebook you will need to create a Google Cloud account and enable billing. The query takes arround three hours to complete. The result is the attached file, commit_history_raw.csv located at the data directory of the forecast folders. You can use the following links to set up your account, or you can run a sample trough my collaborative notebook published at kaggle:  \n","https://www.kaggle.com/code/coronate/github-monitor-data-extraction\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from google.cloud import bigquery\n","import pandas as pd\n","import math\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99307486-b708-437a-8513-a0a31fda1538","_uuid":"445fa22e24fb4790f811d7295f986c633832e864","scrolled":true,"trusted":true},"outputs":[],"source":["\n","client = bigquery.Client()\n","QUERY = \"\"\"\n","        SELECT *\n","        FROM `bigquery-public-data.github_repos.commits`\n","        LIMIT 2000\n","        \"\"\"\n","\n","query_job = client.query(QUERY)\n","\n","iterator = query_job.result(timeout=30)\n","rows = list(iterator)\n","\n","commit_messages = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n","\n","# Look at the first 10 headlines\n","commit_messages.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["query = \"\"\"\n","    SELECT\n","        repo_name, \n","        COUNT(*) AS commit_count,\n","        year, week_number\n","    FROM\n","\n","    (SELECT\n","        ARRAY_TO_STRING(repo_name, ',') AS repo_name,\n","        FORMAT_TIMESTAMP('%Y%m%d', TIMESTAMP_SECONDS(committer.date.seconds)) AS date,\n","        EXTRACT(YEAR FROM TIMESTAMP_SECONDS(committer.date.seconds)) AS year,\n","        EXTRACT(ISOWEEK FROM TIMESTAMP_SECONDS(committer.date.seconds)) AS week_number,\n","        EXTRACT(MONTH FROM TIMESTAMP_SECONDS(committer.date.seconds)) AS month,\n","        EXTRACT(DAY FROM TIMESTAMP_SECONDS(committer.date.seconds)) AS day,\n","    FROM\n","        `bigquery-public-data.github_repos.commits`) A\n","        \n","    GROUP BY\n","        A.repo_name, A.year, A.week_number\n","\"\"\"\n","\n","\n","\n","\n","query_job = client.query(query)\n","iterator = query_job.result()\n","rows = list(iterator)\n","result_df = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["result_df[\"repo_name_single\"] = result_df.repo_name.apply(lambda x:  x.split(\",\")[0].split(\"/\")[1])\n","result_df[\"repo_author_single\"] = result_df.repo_name.apply(lambda x:  x.split(\",\")[0])\n","print(len(result_df[\"repo_name_single\"].unique())) \n","print(len(result_df[\"repo_author_single\"].unique()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","df_checkpoint = result_df[[\"repo_author_single\", \"year\", \"week_number\", \"commit_count\"]]\n","df_checkpoint.to_csv(\"commit_history_raw.csv\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6178,"sourceId":337545,"sourceType":"datasetVersion"}],"dockerImageVersionId":44,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
